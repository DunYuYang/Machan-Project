{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████▋                                   | 181/324 [00:32<00:23,  6.00it/s]"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import cv2\n",
    "from utils.utils import get_yolo_boxes, makedirs\n",
    "from utils.bbox import draw_boxes\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#更改檔案input\n",
    "#input_path   = 'IMG_7534.jpg'\n",
    "input_path   = 'Dunyu.mp4'\n",
    "\n",
    "output_path  = 'output/'\n",
    "makedirs(output_path)\n",
    "\n",
    "# Set some parameter\n",
    "net_h, net_w = 416, 416 # a multiple of 32, the smaller the faster\n",
    "obj_thresh, nms_thresh = 0.5, 0.45\n",
    "anchors = [55,69, 75,234, 133,240, 136,129, 142,363, 203,290, 228,184, 285,359, 341,260]\n",
    "labels = [\"Orange peel\",\"Scratch\",\"Water mark\",\"Granular\",\"Crater\"]\n",
    "\n",
    "# Load the model\n",
    "infer_model = load_model('Machan_dataset.h5')\n",
    "\n",
    "# Predict bounding boxes \n",
    "if input_path[-4:] == '.mp4': # do detection on a video  \n",
    "    video_out = output_path + input_path.split('/')[-1]\n",
    "    video_reader = cv2.VideoCapture(input_path)\n",
    "\n",
    "    nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "    video_writer = cv2.VideoWriter(video_out,\n",
    "                           cv2.VideoWriter_fourcc(*'MPEG'), \n",
    "                           24.0, \n",
    "                           (frame_w, frame_h))\n",
    "    # the main loop\n",
    "    batch_size  = 1\n",
    "    images      = []\n",
    "    start_point = 0 #%\n",
    "    show_window = False\n",
    "    for i in tqdm(range(nb_frames)):\n",
    "        _, image = video_reader.read()\n",
    "        if image is None:\n",
    "            continue\n",
    "        if (float(i+1)/nb_frames) > start_point/100.:\n",
    "            images += [image]\n",
    "\n",
    "            if (i%batch_size == 0) or (i == (nb_frames-1) and len(images) > 0):\n",
    "                # predict the bounding boxes\n",
    "                batch_boxes = get_yolo_boxes(infer_model, images, net_h, net_w, anchors, obj_thresh, nms_thresh)\n",
    "\n",
    "                for i in range(len(images)):\n",
    "                    # draw bounding boxes on the image using labels\n",
    "                    draw_boxes(images[i], batch_boxes[i], labels, obj_thresh)   \n",
    "\n",
    "                    # show the video with detection bounding boxes          \n",
    "                    if show_window: cv2.imshow('video with bboxes', images[i])  \n",
    "\n",
    "                    # write result to the output video\n",
    "                    video_writer.write(images[i]) \n",
    "                images = []\n",
    "            if show_window and cv2.waitKey(1) == 27: break  # esc to quit\n",
    "\n",
    "    if show_window: cv2.destroyAllWindows()\n",
    "    video_reader.release()\n",
    "    video_writer.release()       \n",
    "else: # do detection on an image or a set of images\n",
    "    image_paths = []\n",
    "\n",
    "    if os.path.isdir(input_path): \n",
    "        for inp_file in os.listdir(input_path):\n",
    "            image_paths += [input_path + inp_file]\n",
    "    else:\n",
    "        image_paths += [input_path]\n",
    "\n",
    "    image_paths = [inp_file for inp_file in image_paths if (inp_file[-4:] in ['.jpg', '.png', 'JPEG'])]\n",
    "\n",
    "    # the main loop\n",
    "    for image_path in image_paths:\n",
    "        image = cv2.imread(image_path)\n",
    "        print(image_path)\n",
    "\n",
    "        # predict the bounding boxes\n",
    "        boxes = get_yolo_boxes(infer_model, [image], net_h, net_w, anchors, obj_thresh, nms_thresh)[0]\n",
    "\n",
    "        # draw bounding boxes on the image using labels\n",
    "        draw_boxes(image, boxes, labels, obj_thresh) \n",
    "\n",
    "        # write the image with bounding boxes to file\n",
    "        output_img_path = output_path + image_path.split('/')[-1]\n",
    "        cv2.imwrite(output_img_path, np.uint8(image))\n",
    "        img = cv2.imread(output_img_path)[:,:,::-1]\n",
    "        plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
